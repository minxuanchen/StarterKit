{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 lecture notes\n",
    "\n",
    "\n",
    "## Assignment 1 review\n",
    "\n",
    "### Including directories in paths\n",
    "\n",
    "If you create a file in a lower directory, then want to modify, move, or delete it, you have to use the directory to refer to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir mydirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls > mydirectory/myfiles.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm myfiles.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm mydirectory/myfiles.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls mydirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \">\" vs \">>\"\n",
    "\n",
    "Both \">\" and \">>\" redirect output from the screen to a file.  Both will create new files if none yet exists.  Only \">\" will overwrite an existing file; \">>\" will append to an existing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!date > datefile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat datefile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!date > datefile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat datefile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!date >> datefile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!date >> datefile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat datefile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \".\" and \"..\"\n",
    "\n",
    "These are shorthand names for the current working directory and the parent of the current directory.  You can use them in a variety of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd lecture/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .././lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls .././lecture/../lecture/../lecture/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower|sort|uniq or sort|lower|uniq\n",
    "\n",
    "Order matters!  Consider the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/assignment-1/siddhartha.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' siddhartha.txt | grep -v '^[0-9]' | uniq -c | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the set of three functions: {uniq, lower, sort} there are six orderings.  Which produce which results, and why?\n",
    "\n",
    " * uniq, lower, sort\n",
    " * uniq, sort, lower\n",
    " * sort, lower, uniq\n",
    " * sort, uniq, lower\n",
    " * lower, sort, uniq\n",
    " * lower, uniq, sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' siddhartha.txt | grep -v '^[0-9]' | uniq -c | tr '[:upper:]' '[:lower:]' | sort | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' siddhartha.txt | grep -v '^[0-9]' | uniq -c | sort | tr '[:upper:]' '[:lower:]' | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' siddhartha.txt | grep -v '^[0-9]' | sort | tr '[:upper:]' '[:lower:]' | uniq -c | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' siddhartha.txt | grep -v '^[0-9]' | sort | uniq -c | tr '[:upper:]' '[:lower:]' | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' siddhartha.txt | grep -v '^[0-9]' | tr '[:upper:]' '[:lower:]' | sort | uniq -c | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' siddhartha.txt | grep -v '^[0-9]' | tr '[:upper:]' '[:lower:]' | uniq -c | sort | head "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing grep\n",
    "\n",
    "`grep` is a lot more powerful than what you've seen so far.  More than anything else, it's commonly used to find text within files.  For example, to find lines with \"Romeo\" in Romeo and Juliet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/week-3/romeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep Romeo romeo.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many, many options, such as case-insensitivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -i what romeo.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful one is to print line numbers for matching lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -n Juliet romeo.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also negate certain terms - show non-matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -n Juliet romeo.txt | grep -v Romeo | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an alternate version of the \"one word at a time\" pattern.  It splits lines into words that are at least two characters long, leaving out \"I\" and \"a\" and contractions like \"s\" and \"t\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat romeo.txt | grep -oE '\\w{{2,}}' | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one more useful tip is to match more than one thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep \"Romeo\\|Juliet\" romeo.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing wildcards\n",
    "\n",
    "Sometimes you need to perform a task with a set of files that share a characteristic like a file extension.  The shell lessons had examples with `.pdb` files.  This is common.\n",
    "\n",
    "The `*` (asterisk, or just \"star\") is a wildcard, which matches zero-to-many characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `?` (question mark) is a wildcard that matches exactly one character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp romeo.txt womeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ?omeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls wome?.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is subtle - these two would have worked interchangeably on the above.  But note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls wo*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls wo?.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference?  The `*` can match more than one character; `?` only matches one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing csvkit\n",
    "\n",
    "`csvkit` is a dream to work with.  It's well-documented, does a bunch of things we need to do all the time with data, and its interface is consistent across its many commands.  Please explore its documentation when you can, it does more than just what you'll see in class.\n",
    "\n",
    "Let's look at a large dataset with csvkit.  This is trip data from Capital Bikeshare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/week-3/2017-Q1-cabi-trips-history-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip 2017-Q1-cabi-trips-history-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv 2017-Q1-Trips-History-Data.csv q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What shape does the data take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!csvcut -n q1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do a few records look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head q1.csv | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do that again with a cleaner view of just a few columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head q1.csv | csvcut -c2-3,5,7 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the same thing with the opposite set of columns and `-C` instead of `-c`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head q1.csv | csvcut -C1,4,6,8-9| csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`csvgrep` combines the beauty of `grep` with csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!csvgrep -c5 -r \"8th & F St NE\" q1.csv | head | csvcut -c2-3,5,7 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine csvkit commands with everything else we've learned so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!csvgrep -c5 -r \"8th & F St NE\" q1.csv | csvcut -c2-3,5,7 | csvgrep -c1 -r \"3/31/2017\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!csvgrep -c7 -r \"Eastern Market\" q1.csv | csvcut -c2-3,5,7 | csvgrep -c1 -r \"1/1/2017\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Python filters\n",
    "\n",
    "Starting with the `samplefilter.py` filter, let's write some of our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/week-3/simplefilter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x simplefilter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head romeo.txt | ./simplefilter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, our filter does nothing.  Let's use it as a template to lower-case text.  We'll copy it to a better-named version to be clear what it's for, and we'll add comments that match within the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp simplefilter.py lower.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x lower.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head romeo.txt | ./lower.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to eliminate some words from our counting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Working with GNU Parallel\n",
    "\n",
    "GNU Parallel is an easy to use but very powerful tool with a lot of options.  You can use it to process a lot of data easily and it can also make a big mess in a hurry.  For more examples, see the [tutorial page](https://www.gnu.org/software/parallel/parallel_tutorial.html).\n",
    "\n",
    "Let's start with something we've seen before:  splitting a text file up and counting its unique words.  But let's use a lot of files to do it.\n",
    "\n",
    "**Note**: `parallel` sometimes won't work through the notebook due to an interactive request it makes regarding citation.  If this happens to you, use the terminal directly instead of the notebook if you want to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/week-3/texts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -l texts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir many-texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd many-texts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ../texts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc *.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 668,517 lines and 5,607,822 words from over 100 texts.\n",
    "\n",
    "We can split them up into word counts one at a time like we did in exercise-02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' *.txt \\\n",
    "    | tr '[:upper:]' '[:lower:]' \\\n",
    "    | sort \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I've wrapped lines around by using the `\\` character.  To me, this looks easier to read - you can see each step of the pipeline one at a time.  The `\\` only means \"this shell line continues on the next line\".  The `|` still acts as the pipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold on there\n",
    "\n",
    "That's a lot more (100x) data, and we have to be thoughtful about how we approach it.  \n",
    "\n",
    "Before going any further, let's look at two specific texts first, Romeo and Juliet and Little Women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/week-3/romeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/week-3/women.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' romeo.txt \\\n",
    "    | tr '[:upper:]' '[:lower:]' \\\n",
    "    | sort \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' women.txt \\\n",
    "    | tr '[:upper:]' '[:lower:]' \\\n",
    "    | sort \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Little Women is much longer, which makes sense - it's a novel, not a play.  More text!\n",
    "\n",
    "To compare the two directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l romeo.txt women.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run through both files at once by giving both file names to `grep`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' romeo.txt women.txt \\\n",
    "    | tr '[:upper:]' '[:lower:]' \\\n",
    "    | sort \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do those numbers look right?  \n",
    "\n",
    "Let's take a closer look at what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -oE '\\w{{2,}}' romeo.txt women.txt \\\n",
    "    | tr '[:upper:]' '[:lower:]' \\\n",
    "    | sort \\\n",
    "    | uniq -c \\\n",
    "    | grep \"and\" \\\n",
    "    | tail -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha!  `grep` is not-so-helpfully including the second filename on the lines matched from the second file, but not on the first.  That's why the counts are off.\n",
    "\n",
    "There's probably an option to tell `grep` not to do that.  But let's try something completely different.\n",
    "\n",
    "First, let's break the step into the **data parallel** piece.  For which part of this pipeline is completely data parallel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm all-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls women.txt romeo.txt \\\n",
    "    | parallel --will-cite -j+0 \"grep -oE '\\w{2,}' {} | tr '[:upper:]' '[:lower:]' >> all-words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort all-words.txt \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what we did there?  We parallelized the data, then brought it back together for the rest of the pipeline.\n",
    "\n",
    "Okay, now let's try it on that bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm all-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.txt \\\n",
    "    | parallel --will-cite --eta -j+0 \"grep -oE '\\w{2,}' {} | tr '[:upper:]' '[:lower:]' >> all-words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sort all-words.txt \\\n",
    "    | uniq -c \\\n",
    "    | sort -rn \\\n",
    "    | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that in words:\n",
    "\n",
    "* Time this;\n",
    "* Get a list of all the `*.txt` files in `many-texts/`;\n",
    "* In parallel, extract their words, lower case them, and append them to `many-texts/all-words.txt`;\n",
    "* Sort, find unique words, and get a reverse numeric rank of the top 10 most frequently occurring words.\n",
    "\n",
    "More precisely on that parallel step:\n",
    "\n",
    "* Among all those files listed;\n",
    "* Whenever there is an available core for processing, give it one file to process through the pipeline;\n",
    "* When each job is done, the core is available for processing again;\n",
    "* Continue until there are no jobs waiting.\n",
    "\n",
    "That's data parallelism.\n",
    "\n",
    "### Questions for you\n",
    "\n",
    "How much faster or slower would we go if we did each file one at a time?\n",
    "\n",
    "What's the bottleneck here?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
